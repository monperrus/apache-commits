[
 {
  "author": "liyin", 
  "date": "2013-03-21T18:53:00.112373Z", 
  "msg": [
   "[HBASE-7737] Normalizes stringValue for HServerAddress", 
   "Author: rshroff", 
   "Summary: Always sets the stringValue to host_ip_addr:port.", 
   "Test Plan:", 
   "Added a small unit test.", 
   "MR:", 
   "http://hbaseproxy001.prn1.facebook.com/mr_jt/hbasebackup003-ash3/jobdetails.jsp?jobid=job_201209211223_47720&refresh=30", 
   "Reviewers: liyintang", 
   "Reviewed By: liyintang", 
   "CC: hbase-eng@", 
   "Differential Revision: https://phabricator.fb.com/D695632", 
   "Task ID: 2068631"
  ], 
  "revision_id": "1459458"
 }, 
 {
  "author": "liyin", 
  "date": "2013-03-21T18:52:57.005193Z", 
  "msg": [
   "[HBASE-7734] Fix TestFromClientSide#testFilterAcrossMultipleRegions in trunk.", 
   "Author: manukranthk", 
   "Summary: In RegionScanner.nextRows, checking filter's done value to ensure that null, which was the expected value by the client, was returned. This check was removed when ScanPrefetcher was introduced.", 
   "Test Plan: Ensure Unit tests pass.", 
   "Reviewers: liyintang, kranganathan, aaiyer", 
   "Reviewed By: liyintang", 
   "CC: hbase-eng@", 
   "Differential Revision: https://phabricator.fb.com/D695147", 
   "Task ID: 1980553"
  ], 
  "revision_id": "1459457"
 }, 
 {
  "author": "liyin", 
  "date": "2013-03-21T18:52:54.050639Z", 
  "msg": [
   "[HBASE-7732] Honors the hfile.io.bytes.per.checksum parameter for HFile Writer", 
   "Author: rshroff", 
   "Summary:", 
   "The HFile Writer used to take the default value", 
   "DEFAULT_BYTES_PER_CHECKSUM for bytesPerChecksum. The", 
   "hfile.io.bytes.per.checksum was added to provide an option to change", 
   "this setting. The HFile Writer create() was not reading this", 
   "configuration option. Changed it to read it on every create() call.", 
   "Test Plan:", 
   "Added a small unit test to make sure that the getBytesPerChecksum", 
   "is called and the value from the conf is used.", 
   "More suggestions welcomed.", 
   "MR:", 
   "http://hbaseproxy001.prn1.facebook.com/mr_jt/hbasebackup003-ash3/jobdetails.jsp?jobid=job_201209211223_47382&refresh=30", 
   "Reviewers: liyintang", 
   "Reviewed By: liyintang", 
   "CC: hbase-eng@", 
   "Differential Revision: https://phabricator.fb.com/D694332", 
   "Task ID: 2064279"
  ], 
  "revision_id": "1459456"
 }, 
 {
  "author": "liyin", 
  "date": "2013-03-21T18:52:50.559722Z", 
  "msg": [
   "[HBASE-7707][89-fb] Improved copy table user interface", 
   "Author: adela", 
   "Summary:", 
   "Deleted the functionality of creating a smaller table by scan", 
   "and put. Improved the interface for the users", 
   "Test Plan: tested on my machine", 
   "Reviewers: liyintang", 
   "Reviewed By: liyintang", 
   "CC: hbase-eng@", 
   "Differential Revision: https://phabricator.fb.com/D693127", 
   "Task ID: 2051427"
  ], 
  "revision_id": "1459455"
 }, 
 {
  "author": "liyin", 
  "date": "2013-03-21T18:52:46.795859Z", 
  "msg": [
   "[HBASE-7707][89-fb] A simple tool which will COPY or create a smaller table out of another table", 
   "Author: adela", 
   "Summary:", 
   "as in title, 2 possibilities:", 
   "1) user can bulkupload the old table to a new table", 
   "2) can create smaller table out of a big table by specifying the number of regions (and KVs) which will be copied.", 
   "--- HOW TO RUN THIS---", 
   "> ./bin/hbase org.apache.hadoop.hbase.mapreduce.TableCopyUtils -bl", 
   "Name of the old table: test_table", 
   "Name of the new table: abcb", 
   "Do you want to set start and stop row for the old table scanner? [y/n] n", 
   "(this will create a full copy of table test_table and the new table will be called abcb)", 
   "Test Plan:", 
   "ran this locally on a very small table. Planning to run this", 
   "on tsh25 to create a small table out of cell5_v1 for compaction hook testing.", 
   "Reviewers: liyintang", 
   "Reviewed By: liyintang", 
   "CC: hbase-eng@", 
   "Differential Revision: https://phabricator.fb.com/D686059", 
   "Task ID: 2051427"
  ], 
  "revision_id": "1459454"
 }
]