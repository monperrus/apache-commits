[
 {
  "author": "djencks", 
  "date": "2007-08-16T01:08:50.292371Z", 
  "msg": [
   "GERONIMO-3417 import jaspi spec, copy and update gnodet's partial implementation"
  ], 
  "revision_id": "566460"
 }, 
 {
  "author": "stack", 
  "date": "2007-08-16T01:07:51.114485Z", 
  "msg": [
   "HADOOP-1644 [hbase] Compactions should not block updates", 
   "Disentangles flushes and compactions; flushes can proceed while a", 
   "compaction is happening.  Also, don't compact unless we hit", 
   "compaction threshold: i.e. don't automatically compact on HRegion", 
   "startup so regions can come online the faster.", 
   "M src/contrib/hbase/conf/hbase-default.xml", 
   "(hbase.hregion.compactionThreashold): Moved to be a hstore property", 
   "as part of encapsulating compaction decision inside hstore.", 
   "M src/contrib/hbase/src/test/org/apache/hadoop/hbase/HBaseTestCase.java", 
   "Refactored.  Moved here generalized content loading code that can", 
   "be shared by tests.  Add to setup and teardown the setup and removal", 
   "of local test dir (if it exists).", 
   "M src/contrib/hbase/src/test/org/apache/hadoop/hbase/TestCompare.java", 
   "Added test of HStoreKey compare (It works other than one would at", 
   "first expect).", 
   "M src/contrib/hbase/src/test/org/apache/hadoop/hbase/TestSplit.java", 
   "Bulk of content loading code has been moved up into the parent class.", 
   "M src/contrib/hbase/src/java/org/apache/hadoop/hbase/HConnectionManager.java", 
   "(tableExists): Restore to a check of if the asked-for table is in list of", 
   "tables.  As it was, a check for tableExists would just wait on all timeouts", 
   "and retries to expire and then report table does not exist..  Fixed up", 
   "debug message listing regions of a table.  Added protection against meta", 
   "table not having a COL_REGINFO (Seen in cluster testing -- probably a bug", 
   "in row removal).", 
   "M src/contrib/hbase/src/java/org/apache/hadoop/hbase/HStoreFile.java", 
   "Loading store files, even if it was noticed that there was no corresponding", 
   "map file, was still counting file as valid.  Also fix merger -- was", 
   "constructing MapFile.Reader directly rather than asking HStoreFile for", 
   "the reader (HStoreFile knows how to do MapFile references)", 
   "(rename): Added check that move succeeded and logging.  In cluster-testing,", 
   "the hdfs move of compacted file into place has failed on occasion (Need", 
   "more info).", 
   "M src/contrib/hbase/src/java/org/apache/hadoop/hbase/HStore.java", 
   "Encapsulate ruling on whether a compaction should take place inside HStore.", 
   "Added reading of the compactionThreshold her.  Compaction threshold is", 
   "currently just number of store files.  Later may include other factors such", 
   "as count of reference files.  Cleaned up debug messages around", 
   "reconstruction log.  Removed compaction if size > 1 from constructor.  Let", 
   "compaction happen after we've been deployed (Compactions that happen while", 
   "we are online can continue to take updates.  Compaction in the constructor", 
   "puts off our being able to take in updates).", 
   "(close): Changed so it now returns set of store files.  This used to be done", 
   "by calls to flush. Since flush and compaction have been disentangled, a", 
   "compaction can come in after flush and the list of files could be off.", 
   "Having it done by close, can be sure list of files is complete.", 
   "(flushCache): No longer returns set of store files.  Added 'merging compaction'", 
   "where we pick an arbitrary store file from disk and merge into it the content", 
   "of memcache (Needs work).", 
   "(getAllMapFiles): Renamed getAllStoreFiles.", 
   "(needsCompaction): Added.", 
   "(compactHelper): Added passing of maximum sequence number if already", 
   "calculated. If compacting one file only, we used skip without rewriting", 
   "the info file.  Fixed.", 
   "Refactored.  Moved guts to new  compact(outFile, listOfStores)  method.", 
   "(compact, CompactionReader): Added overrides and interface  to support", 
   "'merging compaction' that takes files and memcache.  In compaction,", 
   "if we failed the move of the compacted file, all data had already been", 
   "deleted.  Changing, so deletion happens after confirmed move of", 
   "compacted file.", 
   "(getFull): Fixed bug where NPE when read of maps came back null.", 
   "Revealed by our NOT compacting stores on startup.  Meant could be two", 
   "backing stores one of which had no data regards queried key.", 
   "(getNMaps): Renamed countOfStoreFiles.", 
   "(toString): Added.", 
   "M src/contrib/hbase/src/java/org/apache/hadoop/hbase/HStoreKey.java", 
   "Added comment on 'odd'-looking comparison.", 
   "M src/contrib/hbase/src/java/org/apache/hadoop/hbase/HRegionServer.java", 
   "Javadoc edit.", 
   "M src/contrib/hbase/src/java/org/apache/hadoop/hbase/HLogEdit.java", 
   "Only return first 128 bytes of value when toStringing (On cluster,", 
   "was returning complete web pages in log).", 
   "M src/contrib/hbase/src/java/org/apache/hadoop/hbase/HMaster.java", 
   "Removed confusing debug message (made sense once -- but not now).", 
   "Test rootRegionLocation for null before using it (can be null).", 
   "M  src/contrib/hbase/src/java/org/apache/hadoop/hbase/HMemcache.java", 
   "Added comment that delete behavior needs study.", 
   "M src/contrib/hbase/src/java/org/apache/hadoop/hbase/HRegion.java", 
   "Fixed merge so it doesn't do the incremental based off files", 
   "returned by flush.  Instead all is done in the one go after", 
   "region closes (using files returned by close).", 
   "Moved duplicated code to new filesByFamily method.", 
   "(WriteState): Removed writesOngoing in favor of compacting and", 
   "flushing flags.", 
   "(flushCache): No longer returns list of files.", 
   "M src/contrib/hbase/src/java/org/apache/hadoop/hbase/util/Writables.java", 
   "Fix javadoc."
  ], 
  "revision_id": "566459"
 }, 
 {
  "author": "jonesde", 
  "date": "2007-08-16T01:05:20.927174Z", 
  "msg": [
   "Added little utility method for getting refurb or original productIds, useful for doing inventory queries by serial number and productId when it may change after refurbishment but keep the same serial number"
  ], 
  "revision_id": "566458"
 }, 
 {
  "author": "vgritsenko", 
  "date": "2007-08-16T01:04:02.976576Z", 
  "msg": [
   "javadoc"
  ], 
  "revision_id": "566457"
 }, 
 {
  "author": "jonesde", 
  "date": "2007-08-16T01:01:37.486487Z", 
  "msg": [
   "Added returnId and returnItemSeqId to InventoryItemDetail for tracking inventory changes based on returns"
  ], 
  "revision_id": "566456"
 }
]