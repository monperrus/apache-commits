[
 {
  "author": "dreiss", 
  "date": "2008-06-11T01:12:58.622078Z", 
  "msg": [
   "Make fake install target for alterl"
  ], 
  "revision_id": "666470"
 }, 
 {
  "author": "dreiss", 
  "date": "2008-06-11T01:12:52.620635Z", 
  "msg": [
   "Add back thrift_server.erl which we still use", 
   "Sorry facebook guys :P We'll switch to thrift_socket_server eventually"
  ], 
  "revision_id": "666469"
 }, 
 {
  "author": "dreiss", 
  "date": "2008-06-11T01:12:45.941608Z", 
  "msg": [
   "Fix thrift_binary_protocol to be hipe-compatible"
  ], 
  "revision_id": "666468"
 }, 
 {
  "author": "dreiss", 
  "date": "2008-06-11T01:12:38.967300Z", 
  "msg": [
   "Change thrift_disk_log_transport to not flush when flush/1 is called if sync_every is defined", 
   "Summary:", 
   "For fast logging we don't want to actually flush to disk after every message.", 
   "There's force_flush/1 now if you actually want to force one"
  ], 
  "revision_id": "666467"
 }, 
 {
  "author": "dreiss", 
  "date": "2008-06-11T01:12:31.881844Z", 
  "msg": [
   "Add thrift_base64_transport which writes base64 encoded data", 
   "Summary:", 
   "This is to make it easy to run Hadoop mapreduces using Hadoop Streaming on thrift-serialized structs", 
   "without implementing any special file splitter or anything", 
   "Test plan: test_disklog:t_base64()"
  ], 
  "revision_id": "666466"
 }
]