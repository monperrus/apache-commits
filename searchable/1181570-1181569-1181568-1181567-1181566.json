[
 {
  "author": "nspiegelberg", 
  "date": "2011-10-11T02:21:23.564377Z", 
  "msg": [
   "Assign regions based on block locality and print out the region locality", 
   "Summary:", 
   "reate a command line tools to print out the region locality info", 
   "Example: running this command line in my dev cluster: 210", 
   "====================", 
   "./bin/hbase localityck", 
   "Host :230. has 13 / 13 blocks for the test1 :", 
   "2d59bb40ffba29ea04fe11b27d997646", 
   "Host :250. has 12 / 12 blocks for the test1 :", 
   "c60bd76550b9c6d5348740f4a41fc9bf", 
   "Host :230. has 12 / 12 blocks for the test1 :", 
   "6fb75bb06213d19171abf816791b2423", 
   "Host :230. has 4 / 4 blocks for the -ROOT- : 70236052", 
   "Host :230. has 12 / 12 blocks for the test1 :", 
   "01c048a618024b38a5f0192614a9660a", 
   "Host :230. has 12 / 12 blocks for the test1 :", 
   "54dd7d26a69c9474f98f54cbdc35cb98", 
   "Host :290. has 4 / 4 blocks for the .META. :", 
   "1028785192", 
   "Host :230. has 12 / 12 blocks for the test1 :", 
   "36dbc39af1465227cb6118fb17da4a20", 
   "Host :230. has 12 / 12 blocks for the test1 :", 
   "4d3958e8ad30bcbe39c037ceb94f3c10", 
   "Host :230. has 12 / 12 blocks for the test1 :", 
   "ced427fa96da9eb3cd9c351ca074a208", 
   "Host :230. has 3 / 3 blocks for the test2 :", 
   "a638e6d34311e2995154679dea73bb8c", 
   "Host :230. has 12 / 12 blocks for the test1 :", 
   "5035d560a22b2a65389c4b6acde9cbf8", 
   "Host :230. has 12 / 12 blocks for the test1 :", 
   "bd55c6af492a684adc573380267bf188", 
   "Host :250. has 12 / 12 blocks for the test1 :", 
   "59534b14cff211e712151be628445aec", 
   "Host :250. has 12 / 12 blocks for the test1 :", 
   "9ec644b196af2d551b3decfc7409ef9b", 
   "Host :230. has 12 / 12 blocks for the test1 :", 
   "0e9416af3be05fb3844d4cac0c4b5198", 
   "Host :250. has 12 / 12 blocks for the test1 :", 
   "59865cdd283215cc2250423d2584d034", 
   "Host :250. has 12 / 12 blocks for the test1 :", 
   "e511fb3efa475866d7b27ac17aea81e4", 
   "Test Plan:", 
   "It has been tested on dev cluster. I will continue working on more test cases", 
   "to stablize the code.", 
   "Reviewed By: kannan", 
   "Reviewers: kannan, kranganathan, gqchen, nspiegelberg, bogdan", 
   "Commenters: dhruba, mbautin", 
   "CC: , hbase@lists, kannan, dhruba, liyintang, mbautin, achao", 
   "Differential Revision: 257279"
  ], 
  "revision_id": "1181570"
 }, 
 {
  "author": "nspiegelberg", 
  "date": "2011-10-11T02:21:18.067227Z", 
  "msg": [
   "A unit test to read a pre-existing version 1 binary HFile", 
   "Summary:", 
   "To make sure the version of HBase with HFile v2 changes stays compatible with", 
   "the legacy HFile format, we need to have a pre-existing binary HFile in the v1", 
   "format and a unit test that reads that binary file using the new HFile v1 reader", 
   "code.", 
   "Test Plan:", 
   "Run the unit test.", 
   "Reviewed By: kannan", 
   "Reviewers: kannan, gqchen", 
   "CC: hbase@lists, , kannan", 
   "Revert Plan:", 
   "OK", 
   "Differential Revision: 269117"
  ], 
  "revision_id": "1181569"
 }, 
 {
  "author": "nspiegelberg", 
  "date": "2011-10-11T02:21:01.466704Z", 
  "msg": [
   "Adding RowMutation for being able to do both Delete and Put in MR jobs", 
   "Summary:", 
   "I have added a union-style class called RowMutation to encapsulate either a", 
   "Delete or a Put in MapReduce jobs.", 
   "This is going to be useful in gathering up mutations for batch import jobs that", 
   "also require deletes to be made available.", 
   "I have also added a matching RowMutationSortReducer modified from the initial", 
   "PutSortReducer so as to know how to sort these elements in a MR job.", 
   "Finally, I added a line for selecting the proper reducer in the", 
   "HFileOutputFormatter, due to the rather hacky nature of checking for instances", 
   "of input...", 
   "Test Plan:", 
   "I've implemented a small unit test which creates a MR job with a mapper that", 
   "statically outputs a Put and a Delete. The new reducer properly sorts them and", 
   "outputs them and the test wil dump to a file using HFileOutputFormat.", 
   "Reviewed By: kannan", 
   "Reviewers: kannan, jfan, nspiegelberg", 
   "Commenters: nspiegelberg, gqchen", 
   "CC: kannan, nspiegelberg, gqchen, bogdan", 
   "Differential Revision: 267252"
  ], 
  "revision_id": "1181568"
 }, 
 {
  "author": "nspiegelberg", 
  "date": "2011-10-11T02:20:57.709813Z", 
  "msg": [
   "Correctly specifying pread and isCompaction in block read API calls", 
   "Summary:", 
   "This fixes incorrectly specified pread (positional-read) and isCompaction", 
   "(determining whether compaction or regular counters will be incremented)", 
   "parameters when calling block reader API functions. These bugs are specific to", 
   "HFile format v2, and were found during compaction workload testing with the", 
   "HFileReadWriteTest tool (266598).", 
   "Also refactoring HFile scanner hierarchy to prevent accidental modifications of", 
   "pread and isCompaction flags.", 
   "Test Plan:", 
   "Run the HFileReadWriteTest tool (266598), and make sure that the number of", 
   "preads is 0 and the number of seek + read operations per second is the same as", 
   "the number of blocks read per second, as reported by the tool.", 
   "Reviewed By: kannan", 
   "Reviewers: kannan, liyintang, pritam", 
   "CC: hbase@lists, , kannan, mbautin", 
   "Revert Plan:", 
   "OK", 
   "Differential Revision: 267302"
  ], 
  "revision_id": "1181567"
 }, 
 {
  "author": "nspiegelberg", 
  "date": "2011-10-11T02:20:53.979252Z", 
  "msg": [
   "add BloomFilter and timestamprange for bulk import", 
   "Summary:", 
   "add BloomFilter and timestamprange for bulk import.", 
   "This is the version updated for hfile v2.", 
   "Test Plan:", 
   "unit tests.", 
   "Reviewed By: kannan", 
   "Reviewers: nspiegelberg, kannan, kranganathan, mbautin", 
   "Commenters: kranganathan, nspiegelberg, mbautin", 
   "CC: hbase@lists, kranganathan, nspiegelberg, gqchen, ,", 
   "mbautin, kannan", 
   "Differential Revision: 237110"
  ], 
  "revision_id": "1181566"
 }
]