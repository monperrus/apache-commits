[
 {
  "author": "hboutemy", 
  "date": "2012-03-31T01:33:21.327956Z", 
  "msg": [
   "keep title in sync with name in pom"
  ], 
  "revision_id": "1307683"
 }, 
 {
  "author": "stroucki", 
  "date": "2012-03-31T01:20:52.318626Z", 
  "msg": [
   "INSTALL: use 0 offset for initial objects", 
   "clustermanagerservice: use network id, not database position to determine default network"
  ], 
  "revision_id": "1307682"
 }, 
 {
  "author": "sebb", 
  "date": "2012-03-31T01:20:21.727534Z", 
  "msg": [
   "Bad word-wrap"
  ], 
  "revision_id": "1307681"
 }, 
 {
  "author": "jboynes", 
  "date": "2012-03-31T01:16:01.873807Z", 
  "msg": [
   "update standard to use released parent pom"
  ], 
  "revision_id": "1307680"
 }, 
 {
  "author": "mikem", 
  "date": "2012-03-31T01:12:49.362031Z", 
  "msg": [
   "DERBY-5624 System can run out of stack space while processing DropOnCommit requests.", 
   "backporting changes #1292079, #1292096, #1292432, and #1292595 from trunk to", 
   "10.8 branch.", 
   "Taking care of cleanup after a commit is handled by notifying all \"Observers\"", 
   "that an event has taken place that they might want to act on and cleanup. In", 
   "the added test case this is triggered by off line commit which effectively", 
   "drops and recreates the base table and all of its indexes after loading the", 
   "data into them.", 
   "Sometimes these Observers may execute work which adds to the Observer queue,", 
   "and that queue can \"miss\" them in the first pass through.", 
   "A previous fix for this problem added a recursive call to notifyObservers in", 
   "the place that could cause this addition of observers. This recursive call", 
   "was causing stack problems when the number of Observers became large. For", 
   "the checked in test case this was 1000 indexes on 1000 columns of the table.", 
   "For other users I believe the cause was a by product of sorts on large disk", 
   "based sorts for multi-gigabyte tables and indexes. 2 users were reporting", 
   "similar failed stacks for failing compresses of large tables, and one was", 
   "able to take this fix to their environment and then successfully run the", 
   "compress.", 
   "The fix was to remove the recursion and instead loop at the outermost point", 
   "until there were no Observers.", 
   "Adding the test to the largedata suite as it takes over 10 minutes to run", 
   "on my machine.", 
   "Only run the testDERBY_5624 in largedata on windows until linux issue resolved.", 
   "Currently on linux with 1024 file descriptors per user this test fails."
  ], 
  "revision_id": "1307679"
 }
]